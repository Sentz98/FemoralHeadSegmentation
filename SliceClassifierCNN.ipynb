{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpappol\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/wandb/run-20231102_172056-h1g38yra</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pappol/Femoral%20Slice%20Classifier/runs/h1g38yra' target=\"_blank\">electric-frog-33</a></strong> to <a href='https://wandb.ai/pappol/Femoral%20Slice%20Classifier' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pappol/Femoral%20Slice%20Classifier' target=\"_blank\">https://wandb.ai/pappol/Femoral%20Slice%20Classifier</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pappol/Femoral%20Slice%20Classifier/runs/h1g38yra' target=\"_blank\">https://wandb.ai/pappol/Femoral%20Slice%20Classifier/runs/h1g38yra</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import wandb\n",
    "from torchvision.transforms import Resize, ToTensor, Normalize, Pad, Compose, RandomRotation, RandomHorizontalFlip, RandomVerticalFlip\n",
    "# Initialize WandB\n",
    "wandb.init(project=\"Femoral Slice Classifier\")\n",
    "\n",
    "\n",
    "class SliceClassifierCNN(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_prob=0.5):\n",
    "        super(SliceClassifierCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.dropout1 = nn.Dropout2d(p=dropout_prob)  # Add dropout\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout2d(p=dropout_prob)  # Add dropout\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.dropout3 = nn.Dropout2d(p=dropout_prob)  # Add dropout\n",
    "        self.fc1 = nn.Linear(128 * 64 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout1(x)  # Apply dropout\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout2(x)  # Apply dropout\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.dropout3(x)  # Apply dropout\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def train_model(self, dataloader, num_epochs, learning_rate, imbalanceTrue):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f'Using device: {device}')\n",
    "        self.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss(weight=torch.tensor([1 - imbalanceTrue, imbalanceTrue]).to(device))\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Wrap your dataloader with tqdm for the progress bar\n",
    "            for inputs, labels in tqdm(dataloader, total=len(dataloader), desc=f'Epoch {epoch + 1}/{num_epochs}', colour='red'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Compute accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            accuracy = correct_predictions / total_samples\n",
    "\n",
    "            wandb.log({\n",
    "                \"Loss\": running_loss / len(dataloader),\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Epoch\": epoch,\n",
    "            })\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader)}, Accuracy: {accuracy}')\n",
    "\n",
    "        print('Training complete!')\n",
    "\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "        print(f'Model saved to {model_path}')\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, model_path, num_classes):\n",
    "        model = cls(num_classes)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        return model    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceClassifierResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SliceClassifierResNet, self).__init__()\n",
    "        # Load a pretrained ResNet-18 model\n",
    "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        \n",
    "        # Change the first layer to accept 1 channel input\n",
    "        self.resnet.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        \n",
    "        # Freeze all layers except the final classifier layer\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet.fc.requires_grad = True\n",
    "\n",
    "        # Modify the final classifier layer to match the number of classes\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n",
    "\n",
    "    def train_model(self, dataloader, num_epochs, learning_rate):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f'Using device: {device}')\n",
    "        self.to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.train()\n",
    "            running_loss = 0.0\n",
    "            correct_predictions = 0\n",
    "            total_samples = 0\n",
    "\n",
    "            # Wrap your dataloader with tqdm for the progress bar\n",
    "            for inputs, labels in tqdm(dataloader, total=len(dataloader), desc=f'Epoch {epoch + 1}/{num_epochs}', colour='red'):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                # Compute accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                correct_predictions += (predicted == labels).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "            accuracy = correct_predictions / total_samples\n",
    "\n",
    "            wandb.log({\n",
    "                \"Loss\": running_loss / len(dataloader),\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Epoch\": epoch,\n",
    "            })\n",
    "\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss / len(dataloader)}, Accuracy: {accuracy}')\n",
    "\n",
    "        print('Training complete!')\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        torch.save(self.state_dict(), model_path)\n",
    "        print(f'Model saved to {model_path}')\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, model_path, num_classes):\n",
    "        model = cls(num_classes)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_and_std(dataset):\n",
    "    \"\"\"\n",
    "    Calculate the mean and standard deviation of a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset (Dataset): a PyTorch Dataset object that returns images.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (mean, std) of the dataset.\n",
    "    \"\"\"\n",
    "    loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=False, num_workers=4)\n",
    "\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    total_images = 0\n",
    "\n",
    "    for images, _ in loader:\n",
    "        # Assuming images are stacked in shape (B, C, H, W)\n",
    "        # where B is the batch size, C is the number of channels,\n",
    "        # H is the height and W is the width of the image.\n",
    "\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images += batch_samples\n",
    "\n",
    "    mean /= total_images\n",
    "    std /= total_images\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadToSquare:\n",
    "    def __init__(self, fill):\n",
    "        self.fill = fill\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert tensor to PIL Image if it's a tensor\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = to_pil_image(img)\n",
    "        \n",
    "        # Calculate padding\n",
    "        width, height = img.size\n",
    "        max_wh = max(width, height)\n",
    "        pad_width = (max_wh - width) // 2\n",
    "        pad_height = (max_wh - height) // 2\n",
    "        padding = (pad_width, pad_height, pad_width if width % 2 == 0 else pad_width + 1, pad_height if height % 2 == 0 else pad_height + 1)\n",
    "        \n",
    "        # Pad and return image\n",
    "        img = Pad(padding, fill=self.fill)(img)\n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SliceDatasetBuilder import CustomHipDataset\n",
    "import datetime\n",
    "\n",
    "json_path = \"label.json\"  # Update this to the path where your image dataset is located\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "date = datetime.datetime.now().strftime(\"%H%M%S\")\n",
    "model_path = f\"modelCNN_{date}.pth\"\n",
    "\n",
    "mean = 0.2143\n",
    "std = 0.1621\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data/dataset/normalHip/JOR01/axial...\n",
      "Positive interval of JOR01: [330, 400] for SX\n",
      "Positive interval of JOR01: [280, 370] for DX\n",
      "Loading data/dataset/normalHip/JOR02/axial...\n",
      "Positive interval of JOR02: [250, 380] for SX\n",
      "Positive interval of JOR02: [340, 445] for DX\n",
      "Loading data/dataset/normalHip/JOR09/axial...\n",
      "Positive interval of JOR09: [240, 300] for SX\n",
      "Positive interval of JOR09: [230, 290] for DX\n",
      "Loading data/dataset/dysplasticHip/TRAD09/axial...\n",
      "Positive interval of TRAD09: [130, 190] for SX\n",
      "Positive interval of TRAD09: [255, 320] for DX\n",
      "Loading data/dataset/dysplasticHip/TRAD10/axial...\n",
      "Positive interval of TRAD10: [355, 430] for SX\n",
      "Positive interval of TRAD10: [230, 325] for DX\n",
      "Loading data/dataset/retrovertedHip/Patient_01/axial...\n",
      "Positive interval of Patient_01: [210, 270] for SX\n",
      "Positive interval of Patient_01: [200, 260] for DX\n",
      "Loading data/dataset/retrovertedHip/Patient_02/axial...\n",
      "Positive interval of Patient_02: [230, 285] for SX\n",
      "Positive interval of Patient_02: [260, 310] for DX\n",
      "Total number of samples: 9824\n",
      "Number of positive samples: 903\n",
      "Number of negative samples: 8921\n",
      "Imbalance ratio: 0.09\n"
     ]
    }
   ],
   "source": [
    "transform = Compose([\n",
    "    RandomRotation(degrees=(-10, 10)),  # Randomly rotate the image within the range of -10 to 10 degrees\n",
    "    RandomHorizontalFlip(0.5),  # Randomly flip the image horizontally\n",
    "    RandomVerticalFlip(0.5),  # Randomly flip the image vertically\n",
    "    PadToSquare(fill=mean),  # Pad the image to make it square\n",
    "    Resize((512, 512)),  # Resize the image to the desired size\n",
    "    ToTensor(),\n",
    "    Normalize(mean, std)  # Normalize with the dataset's mean and std\n",
    "])\n",
    "\n",
    "dataset = CustomHipDataset(json_path,['axial'], transform=transform)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Plot some info about the dataset\n",
    "print(f'Total number of samples: {len(dataset)}')\n",
    "image_paths, labels = dataset.get_all_dataset()\n",
    "print(f'Number of positive samples: {sum(labels)}')\n",
    "print(f'Number of negative samples: {len(labels) - sum(labels)}')\n",
    "\n",
    "imbalanceTrue = round(sum(labels) / len(labels), 2)\n",
    "print(f'Imbalance ratio: {imbalanceTrue}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|\u001b[31m██████████\u001b[0m| 307/307 [03:52<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 2.0359769478438485, Accuracy: 0.9006514657980456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5: 100%|\u001b[31m██████████\u001b[0m| 307/307 [03:39<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Loss: 0.12186172155736177, Accuracy: 0.9071661237785016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5: 100%|\u001b[31m██████████\u001b[0m| 307/307 [03:44<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Loss: 0.06570267538343448, Accuracy: 0.9080822475570033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5: 100%|\u001b[31m██████████\u001b[0m| 307/307 [03:46<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Loss: 0.05426401501170326, Accuracy: 0.9097109120521173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5: 100%|\u001b[31m██████████\u001b[0m| 307/307 [03:47<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Loss: 0.047537715978926524, Accuracy: 0.9125610749185668\n",
      "Training complete!\n",
      "Model saved to modelCNN_172058.pth\n"
     ]
    }
   ],
   "source": [
    "# Select model\n",
    "TRAIN = True\n",
    "\n",
    "if TRAIN:\n",
    "    #model = SliceClassifierResNet(num_classes)\n",
    "    model = SliceClassifierCNN(num_classes)\n",
    "    # Train the model \n",
    "    model.train_model(dataloader, num_epochs, learning_rate, imbalanceTrue)\n",
    "    model.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 100\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "#TEST CLASSIFIER\n",
    "loaded = SliceClassifierCNN.load_model('modelCNN_172058.pth', num_classes)\n",
    "loaded.eval()\n",
    "\n",
    "# Load images from a folder\n",
    "folder_path = \"data/dataset/retrovertedHip/Patient_06/axial\"\n",
    "\n",
    "image_array = []\n",
    "for filename in os.listdir(folder_path):\n",
    "        # Sample every 10 images\n",
    "        if int(filename.split('_')[-2]) % 20 != 0:\n",
    "                continue\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        image = Image.open(file_path).convert(\"RGB\").convert(\"L\")\n",
    "        if transform is not None:\n",
    "                image = transform(image)\n",
    "        image_array.append(image)\n",
    "\n",
    "print(f'Number of images: {len(image_array)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the loaded model\n",
    "predictions = []\n",
    "for image in image_array:\n",
    "    image = image.unsqueeze(0)\n",
    "    predictions.append(loaded(image))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the predictions\n",
    "for index, value in enumerate(predictions):\n",
    "    # Get the predicted class with the highest score\n",
    "    pred_class = value.argmax(dim=1, keepdim=True)\n",
    "    if pred_class.item() == 1:\n",
    "        print(f'{index + 1}: Normal')\n",
    "        plt.imshow(image_array[index].squeeze(), cmap='gray')\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pappol/anaconda3/envs/medical/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/pappol/anaconda3/envs/medical/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_model() takes 4 positional arguments but 5 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb Cella 11\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.87.232.58/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m SliceClassifierResNet(num_classes)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.87.232.58/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m#model = SliceClassifierCNN(num_classes)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.87.232.58/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Train the model \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B100.87.232.58/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mtrain_model(dataloader, num_epochs, learning_rate, imbalanceTrue)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B100.87.232.58/home/pappol/Scrivania/uni/medical/FemoralHeadSegmentation/SliceClassifierCNN.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39msave_model(model_path)\n",
      "\u001b[0;31mTypeError\u001b[0m: train_model() takes 4 positional arguments but 5 were given"
     ]
    }
   ],
   "source": [
    "if TRAIN:\n",
    "    model = SliceClassifierResNet(num_classes)\n",
    "    #model = SliceClassifierCNN(num_classes)\n",
    "    # Train the model \n",
    "    model.train_model(dataloader, num_epochs, learning_rate, imbalanceTrue)\n",
    "    model.save_model(model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medImg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
