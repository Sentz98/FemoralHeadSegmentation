{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "exclusionInterval = 20\n",
    "\n",
    "class CustomHipDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, json_path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            json_path (string): Path to the JSON file with annotations.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        with open(json_path, 'r') as file:\n",
    "            data_info = json.load(file)\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for subj_info in data_info:\n",
    "            subj_name = subj_info[\"subj\"]\n",
    "            for view_type in [\"axial\", \"coronal\", \"sagittal\"]:\n",
    "                image_dir = os.path.join(subj_info[\"folder\"], subj_name, view_type)\n",
    "\n",
    "                # Determine if the view type differentiates between DX and SX\n",
    "                sides = [\"DX\", \"SX\"] if view_type in [\"axial\", \"coronal\"] else [None]\n",
    "\n",
    "                for side_idx, side in enumerate(sides):\n",
    "                    positive_interval = subj_info[view_type][side_idx]\n",
    "                    excluded_interval = [\n",
    "                        max(0, positive_interval[0] - exclusionInterval),\n",
    "                        positive_interval[1] + exclusionInterval\n",
    "                    ]\n",
    "\n",
    "                    for image_name in os.listdir(image_dir):\n",
    "                        # Validate if the image matches the side for non-sagittal types\n",
    "                        if side and not image_name.endswith(f\"_{side}.png\"):\n",
    "                            continue\n",
    "\n",
    "                        # Extract the image number\n",
    "                        img_num = int(image_name.split('_')[1].split('.')[0])\n",
    "\n",
    "                        # Exclude images within the excluded interval\n",
    "                        if excluded_interval[0] <= img_num <= positive_interval[0] or positive_interval[1] <= img_num <= excluded_interval[1]:\n",
    "                            continue\n",
    "\n",
    "                        # Label as positive if within the positive interval\n",
    "                        label = positive_interval[0] <= img_num <= positive_interval[1]\n",
    "\n",
    "                        self.image_paths.append(os.path.join(image_dir, image_name))\n",
    "                        self.labels.append(label)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.image_paths[index]\n",
    "        image = Image.open(img_path).convert(\"RGB\").convert(\"L\")\n",
    "\n",
    "        image = np.array(image)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(self.labels[index], dtype=torch.float32)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def load_all_dataset(self):\n",
    "        self.__images__ = []\n",
    "        self.__labels__ = []\n",
    "        for i in tqdm(range(self.__len__()), \"Load all dataset\"):\n",
    "            img, label = self.__getitem__(i)\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        \n",
    "            self.__images__.append(img)\n",
    "            self.__labels__.append(label)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    def get_all_dataset(self):\n",
    "        return self.__images__, self.__labels__\n",
    "\n",
    "# Usage:\n",
    "# dataset = CustomHipDataset(\"your_json_path.json\")\n",
    "# data_loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "class SliceSVMClassifier:\n",
    "    def __init__(self, kernel='linear', C=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the ImageSVMClassifierWithHOG.\n",
    "\n",
    "        :param kernel: SVM kernel (default: 'linear')\n",
    "        :param C: Regularization parameter (default: 1.0)\n",
    "        \"\"\"\n",
    "        self.clf = svm.SVC(kernel=kernel, C=C)\n",
    "\n",
    "    def _extract_hog_features(self, images):\n",
    "        hog_features = []\n",
    "        for image in tqdm(images, desc=\"Extracting HOG Features\"):\n",
    "            image = resize(image, (128, 128))\n",
    "            # Extract HOG features\n",
    "            fd = hog(image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), block_norm='L2-Hys')\n",
    "\n",
    "            hog_features.append(fd)\n",
    "        return np.array(hog_features)\n",
    "\n",
    "    def train(self, custom_dataset, test_size=0.2, random_state=None):\n",
    "        \"\"\"\n",
    "        Train the SVM classifier with HOG features using a CustomHipDataset.\n",
    "\n",
    "        :param custom_dataset: CustomHipDataset object\n",
    "        :param test_size: Fraction of data to use for testing (default: 0.2)\n",
    "        :param random_state: Random seed for reproducibility\n",
    "        \"\"\"\n",
    "        X = custom_dataset[0]\n",
    "        y = custom_dataset[1]\n",
    "\n",
    "        hog_features = self._extract_hog_features(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(hog_features, y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # Train the classifier and update the progress bar\n",
    "        self.clf.fit(X_train, y_train)\n",
    "\n",
    "        accuracy = self.clf.score(X_test, y_test)\n",
    "        return accuracy\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Make predictions using the trained SVM classifier with HOG features using a CustomHipDataset.\n",
    "\n",
    "        :param custom_dataset: CustomHipDataset object\n",
    "        :return: List of predicted labels\n",
    "        \"\"\"\n",
    "        hog_features = self._extract_hog_features(X)\n",
    "        predictions = self.clf.predict(hog_features)\n",
    "        return predictions\n",
    "    \n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Save the trained SVM classifier model to a file using joblib.\n",
    "\n",
    "        :param filename: Name of the file to save the model to\n",
    "        \"\"\"\n",
    "        joblib.dump(self.clf, filename)\n",
    "    \n",
    "    def load_model(self, filename):\n",
    "        \"\"\"\n",
    "        Load a trained SVM classifier model from a file using joblib.\n",
    "\n",
    "        :param filename: Name of the file to load the model from\n",
    "        :return: An instance of SliceSVMClassifier with the loaded model\n",
    "        \"\"\"\n",
    "        self.clf = joblib.load(filename)\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load all dataset: 100%|██████████| 6472/6472 [02:35<00:00, 41.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "hips = CustomHipDataset(\"TEST.json\")\n",
    "hips.load_all_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting HOG Features: 100%|██████████| 6472/6472 [07:47<00:00, 13.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SVM classifier\n",
    "\n",
    "svm_classifier = SliceSVMClassifier()\n",
    "\n",
    "# Train the SVM classifier with HOG features\n",
    "accuracy = svm_classifier.train(hips.get_all_dataset(), random_state=42)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Save the trained model to a file\n",
    "svm_classifier.save_model(\"svm_classifier_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from a file\n",
    "loaded_classifier = SliceSVMClassifier.load_model(\"svm_classifier_model.pkl\")\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "#predictions = loaded_classifier.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medImg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
